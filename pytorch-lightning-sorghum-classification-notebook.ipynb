{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -qq albumentations==1.0.3\n!pip install wandb --upgrade\n!pip install timm\n# !conda install -y torchtext -c pytorch","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:23:50.302920Z","iopub.execute_input":"2022-04-04T07:23:50.303313Z","iopub.status.idle":"2022-04-04T07:24:16.290789Z","shell.execute_reply.started":"2022-04-04T07:23:50.303225Z","shell.execute_reply":"2022-04-04T07:24:16.289949Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport cv2\nimport timm\nimport torch\nimport torch.nn as nn\nimport albumentations as A\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\nimport torchmetrics\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom albumentations.core.composition import Compose, OneOf\nfrom albumentations.pytorch import ToTensorV2\n\nfrom pytorch_lightning import Trainer, seed_everything\nfrom pytorch_lightning import Callback\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.loggers import WandbLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:24:16.292838Z","iopub.execute_input":"2022-04-04T07:24:16.293106Z","iopub.status.idle":"2022-04-04T07:24:22.290497Z","shell.execute_reply.started":"2022-04-04T07:24:16.293062Z","shell.execute_reply":"2022-04-04T07:24:22.289780Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print(f\"PyTorch Lightning version: {pl.__version__}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:24:34.025216Z","iopub.execute_input":"2022-04-04T07:24:34.025783Z","iopub.status.idle":"2022-04-04T07:24:34.029970Z","shell.execute_reply.started":"2022-04-04T07:24:34.025744Z","shell.execute_reply":"2022-04-04T07:24:34.029270Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\n\nclass CFG:\n    proj_name = 'Sorghum Kaggle Competition'\n    seed = 42\n    model_name = 'tf_efficientnet_b3_ns'\n    pretrained = True\n    img_size = 512\n    num_classes = 100\n    lr = 1e-4\n    max_lr = 1e-3\n    pct_start = 0.2\n    div_factor = 1.0e+3\n    final_div_factor = 1.0e+3\n    num_epochs = 20\n    batch_size = 16\n    accum = 1\n    precision = 16\n    n_fold = 4\n    penalty = 2\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:24:34.356100Z","iopub.execute_input":"2022-04-04T07:24:34.356639Z","iopub.status.idle":"2022-04-04T07:24:34.426450Z","shell.execute_reply.started":"2022-04-04T07:24:34.356595Z","shell.execute_reply":"2022-04-04T07:24:34.425393Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"seed_everything(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:24:34.576073Z","iopub.execute_input":"2022-04-04T07:24:34.576617Z","iopub.status.idle":"2022-04-04T07:24:34.588921Z","shell.execute_reply.started":"2022-04-04T07:24:34.576563Z","shell.execute_reply":"2022-04-04T07:24:34.588183Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"PATH = \"../input/sorghum-id-fgvc-9/\"\n\n# TRAIN_DIR = PATH + 'train_images/'\nTRAIN_DIR = \"../input/sorghum-id-fgvc-9/train_images/\"\nTEST_DIR = PATH + 'test/'","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:24:36.974876Z","iopub.execute_input":"2022-04-04T07:24:36.975164Z","iopub.status.idle":"2022-04-04T07:24:36.980345Z","shell.execute_reply.started":"2022-04-04T07:24:36.975134Z","shell.execute_reply":"2022-04-04T07:24:36.979486Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(PATH + \"train_cultivar_mapping.csv\")\nprint(len(data))\ndata.dropna(inplace=True)\nprint(len(data))\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:24:37.264634Z","iopub.execute_input":"2022-04-04T07:24:37.265166Z","iopub.status.idle":"2022-04-04T07:24:37.322112Z","shell.execute_reply.started":"2022-04-04T07:24:37.265132Z","shell.execute_reply":"2022-04-04T07:24:37.321433Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def remove_missing_images(data):\n    images = data['image'].values\n    indices = []\n    for i in range(data.shape[0]):\n        im = data.image.iloc[i]\n        if not os.path.exists(os.path.join(TRAIN_DIR, im)):\n            indices.append(i)\n    data = data.drop(indices, axis=0).reset_index(drop=True)\n    return data\n\ndata = remove_missing_images(data)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:24:38.735976Z","iopub.execute_input":"2022-04-04T07:24:38.736525Z","iopub.status.idle":"2022-04-04T07:25:15.126814Z","shell.execute_reply.started":"2022-04-04T07:24:38.736487Z","shell.execute_reply":"2022-04-04T07:25:15.126050Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:25:15.128499Z","iopub.execute_input":"2022-04-04T07:25:15.128748Z","iopub.status.idle":"2022-04-04T07:25:15.137883Z","shell.execute_reply.started":"2022-04-04T07:25:15.128715Z","shell.execute_reply":"2022-04-04T07:25:15.137130Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"unique_cultivars = list(data[\"cultivar\"].unique())\nnum_classes = len(unique_cultivars)\n\nCFG.num_classes = num_classes\nprint(num_classes)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:25:15.139064Z","iopub.execute_input":"2022-04-04T07:25:15.139622Z","iopub.status.idle":"2022-04-04T07:25:15.148549Z","shell.execute_reply.started":"2022-04-04T07:25:15.139574Z","shell.execute_reply":"2022-04-04T07:25:15.147660Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data[\"file_path\"] = data[\"image\"].apply(lambda image: TRAIN_DIR + image)\ndata[\"cultivar_index\"] = data[\"cultivar\"].map(lambda item: unique_cultivars.index(item))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:25:15.150817Z","iopub.execute_input":"2022-04-04T07:25:15.151409Z","iopub.status.idle":"2022-04-04T07:25:15.202041Z","shell.execute_reply.started":"2022-04-04T07:25:15.151351Z","shell.execute_reply":"2022-04-04T07:25:15.201404Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"if DEBUG == True:\n    data = data[:200]\n    CFG.num_epochs = 10","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:25:15.202954Z","iopub.execute_input":"2022-04-04T07:25:15.203181Z","iopub.status.idle":"2022-04-04T07:25:15.206978Z","shell.execute_reply.started":"2022-04-04T07:25:15.203149Z","shell.execute_reply":"2022-04-04T07:25:15.206329Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n\nfor train_idx, valid_idx in skf.split(data['image'], data[\"cultivar_index\"]):\n    df_train = data.iloc[train_idx]\n    df_valid = data.iloc[valid_idx]\n\nprint(f\"train size: {len(df_train)}\")\nprint(f\"valid size: {len(df_valid)}\")\n\nprint(df_train.cultivar.value_counts())\nprint(df_valid.cultivar.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:25:15.208328Z","iopub.execute_input":"2022-04-04T07:25:15.209074Z","iopub.status.idle":"2022-04-04T07:25:15.245213Z","shell.execute_reply.started":"2022-04-04T07:25:15.209037Z","shell.execute_reply":"2022-04-04T07:25:15.244572Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class SorghumDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.image_path = df['file_path'].values\n        self.labels = df[\"cultivar_index\"].values\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n        \n        image_path = self.image_path[idx]\n        image = cv2.imread(image_path)\n        \n        augmented = self.transform(image=image)\n        image = augmented['image']\n        return {'image':image, 'target': label}","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:25:15.246331Z","iopub.execute_input":"2022-04-04T07:25:15.246653Z","iopub.status.idle":"2022-04-04T07:25:15.254137Z","shell.execute_reply.started":"2022-04-04T07:25:15.246618Z","shell.execute_reply":"2022-04-04T07:25:15.253343Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def get_transform(phase: str):\n    if phase == 'train':\n        return Compose([\n            A.RandomResizedCrop(height=CFG.img_size, width=CFG.img_size),\n            A.Flip(p=0.5),\n            A.RandomRotate90(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.HueSaturationValue(p=0.5),\n            A.OneOf([\n                A.RandomBrightnessContrast(p=0.5),\n                A.RandomGamma(p=0.5),\n            ], p=0.5),\n            A.OneOf([\n                A.Blur(p=0.1),\n                A.GaussianBlur(p=0.1),\n                A.MotionBlur(p=0.1),\n            ], p=0.1),\n            A.OneOf([\n                A.GaussNoise(p=0.1),\n                A.ISONoise(p=0.1),\n                A.GridDropout(ratio=0.5, p=0.2),\n                A.CoarseDropout(max_holes=16, min_holes=8, max_height=16, max_width=16, min_height=8, min_width=8, p=0.2)\n            ], p=0.2),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n    else:\n        return Compose([\n            A.Resize(height=CFG.img_size, width=CFG.img_size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:25:15.255557Z","iopub.execute_input":"2022-04-04T07:25:15.255884Z","iopub.status.idle":"2022-04-04T07:25:15.268852Z","shell.execute_reply.started":"2022-04-04T07:25:15.255848Z","shell.execute_reply":"2022-04-04T07:25:15.268010Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class FocalLoss(nn.modules.loss._WeightedLoss):\n    def __init__(self, weight=None, gamma=CFG.penalty,reduction='mean'):\n        super(FocalLoss, self).__init__(weight,reduction=reduction)\n        self.gamma = gamma\n        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n\n    def forward(self, input, target):\n\n        ce_loss = F.cross_entropy(input, target,reduction=self.reduction,weight=self.weight)\n        pt = torch.exp(-ce_loss)\n        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n        return focal_loss","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:25:15.270042Z","iopub.execute_input":"2022-04-04T07:25:15.270457Z","iopub.status.idle":"2022-04-04T07:25:15.281838Z","shell.execute_reply.started":"2022-04-04T07:25:15.270422Z","shell.execute_reply":"2022-04-04T07:25:15.281016Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_dataset = SorghumDataset(df_train, get_transform('train'))\nvalid_dataset = SorghumDataset(df_valid, get_transform('valid'))\n\ntrain_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, pin_memory=True, drop_last=True, num_workers=2)\nvalid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, pin_memory=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:25:15.284750Z","iopub.execute_input":"2022-04-04T07:25:15.285079Z","iopub.status.idle":"2022-04-04T07:25:15.293580Z","shell.execute_reply.started":"2022-04-04T07:25:15.285028Z","shell.execute_reply":"2022-04-04T07:25:15.292782Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"CFG.steps_per_epoch = len(train_loader)\nCFG.steps_per_epoch","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:25:15.294861Z","iopub.execute_input":"2022-04-04T07:25:15.295239Z","iopub.status.idle":"2022-04-04T07:25:15.308086Z","shell.execute_reply.started":"2022-04-04T07:25:15.295201Z","shell.execute_reply":"2022-04-04T07:25:15.307151Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class CustomEffNet(nn.Module):\n    def __init__(self, model_name='tf_efficientnet_b0_ns', pretrained=True):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.model.get_classifier().in_features\n#         self.model.fc = nn.Linear(in_features, CFG.num_classes)\n        self.model.classifier = nn.Sequential(\n            nn.Linear(in_features, in_features),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(in_features, CFG.num_classes)\n        )\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:25:15.309256Z","iopub.execute_input":"2022-04-04T07:25:15.309907Z","iopub.status.idle":"2022-04-04T07:25:15.317403Z","shell.execute_reply.started":"2022-04-04T07:25:15.309870Z","shell.execute_reply":"2022-04-04T07:25:15.316663Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class LitSorghum(pl.LightningModule):\n    def __init__(self, model):\n        super(LitSorghum, self).__init__()\n        self.model = model\n        self.metric = torchmetrics.Accuracy(threshold=0.5, num_classes=CFG.num_classes)\n        self.criterion = FocalLoss()\n        self.lr = CFG.lr\n\n    def forward(self, x, *args, **kwargs):\n        return self.model(x)\n\n    def configure_optimizers(self):\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optimizer, \n                                                             epochs=CFG.num_epochs, steps_per_epoch=CFG.steps_per_epoch,\n                                                             max_lr=CFG.max_lr, pct_start=CFG.pct_start, \n                                                             div_factor=CFG.div_factor, final_div_factor=CFG.final_div_factor)\n        scheduler = {'scheduler': self.scheduler, 'interval': 'step',}\n\n        return [self.optimizer], [scheduler]\n\n    def training_step(self, batch, batch_idx):\n        image = batch['image']\n        target = batch['target'].long()\n        output = self.model(image)\n        loss = self.criterion(output, target)\n        score = self.metric(output.argmax(1), target)\n        logs = {'train_loss': loss, 'train_acc': score, 'lr': self.optimizer.param_groups[0]['lr']}\n        self.log_dict(\n            logs,\n            on_step=False, on_epoch=True, prog_bar=True, logger=True\n        )\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        image = batch['image']\n        target = batch['target'].long()\n        output = self.model(image)\n        loss = self.criterion(output, target)\n        score = self.metric(output.argmax(1), target)\n        logs = {'valid_loss': loss, 'valid_acc': score}\n        self.log_dict(\n            logs,\n            on_step=False, on_epoch=True, prog_bar=True, logger=True\n        )\n        return loss","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:25:15.318869Z","iopub.execute_input":"2022-04-04T07:25:15.319424Z","iopub.status.idle":"2022-04-04T07:25:15.334107Z","shell.execute_reply.started":"2022-04-04T07:25:15.319391Z","shell.execute_reply":"2022-04-04T07:25:15.333495Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model = CustomEffNet(model_name=CFG.model_name, pretrained=CFG.pretrained)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:25:15.335524Z","iopub.execute_input":"2022-04-04T07:25:15.335816Z","iopub.status.idle":"2022-04-04T07:28:08.548745Z","shell.execute_reply.started":"2022-04-04T07:25:15.335784Z","shell.execute_reply":"2022-04-04T07:28:08.547929Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"lit_model = LitSorghum(model.model)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:28:08.553777Z","iopub.execute_input":"2022-04-04T07:28:08.554151Z","iopub.status.idle":"2022-04-04T07:28:08.559339Z","shell.execute_reply.started":"2022-04-04T07:28:08.554097Z","shell.execute_reply":"2022-04-04T07:28:08.558703Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"logger = CSVLogger(save_dir='logs/', name=CFG.model_name)\nlogger.log_hyperparams(CFG.__dict__)\ncheckpoint_callback = ModelCheckpoint(monitor='valid_loss',\n                                      save_top_k=1,\n                                      save_last=True,\n                                      save_weights_only=True,\n                                      filename='{epoch:02d}-{valid_loss:.4f}-{valid_acc:.4f}',\n                                      verbose=False,\n                                      mode='min')\n\ntrainer = Trainer(\n    max_epochs=CFG.num_epochs,\n    gpus=[0],\n    accumulate_grad_batches=CFG.accum,\n    precision=CFG.precision,\n    callbacks=[checkpoint_callback], \n    logger=logger,\n    weights_summary='top',\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:28:08.560698Z","iopub.execute_input":"2022-04-04T07:28:08.561172Z","iopub.status.idle":"2022-04-04T07:28:08.583161Z","shell.execute_reply.started":"2022-04-04T07:28:08.561135Z","shell.execute_reply":"2022-04-04T07:28:08.582526Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"trainer.fit(lit_model, train_dataloaders=train_loader, val_dataloaders=valid_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:28:08.585846Z","iopub.execute_input":"2022-04-04T07:28:08.586484Z","iopub.status.idle":"2022-04-04T13:06:22.843858Z","shell.execute_reply.started":"2022-04-04T07:28:08.586448Z","shell.execute_reply":"2022-04-04T13:06:22.843056Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"!ls \"./logs/tf_efficientnet_b3_ns/version_0/checkpoints/\"","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:07:54.367276Z","iopub.execute_input":"2022-04-04T13:07:54.367897Z","iopub.status.idle":"2022-04-04T13:07:55.181189Z","shell.execute_reply.started":"2022-04-04T13:07:54.367857Z","shell.execute_reply":"2022-04-04T13:07:55.180403Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = CustomEffNet(model_name=CFG.model_name, pretrained=False)\ncheckpoint = \"./logs/tf_efficientnet_b3_ns/version_0/checkpoints/last.ckpt\"\nmodel.load_state_dict(torch.load(checkpoint)['state_dict'])","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:07:58.570055Z","iopub.execute_input":"2022-04-04T13:07:58.570567Z","iopub.status.idle":"2022-04-04T13:07:58.988487Z","shell.execute_reply.started":"2022-04-04T13:07:58.570529Z","shell.execute_reply":"2022-04-04T13:07:58.987685Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\ntrain_acc = metrics['train_acc'].dropna().reset_index(drop=True)\nvalid_acc = metrics['valid_acc'].dropna().reset_index(drop=True)\n\nfig, axes = plt.subplots(1,3, figsize = (12,4))\n\naxes[0].grid(True)\naxes[0].plot(train_acc, color=\"r\", marker=\"o\", label='train/acc')\naxes[0].plot(valid_acc, color=\"b\", marker=\"x\", label='valid/acc')\naxes[0].legend(loc='lower right', fontsize=9)\n\ntrain_loss = metrics['train_loss'].dropna().reset_index(drop=True)\nvalid_loss = metrics['valid_loss'].dropna().reset_index(drop=True)\n\naxes[1].grid(True)\naxes[1].plot(train_loss, color=\"r\", marker=\"o\", label='train/loss')\naxes[1].plot(valid_loss, color=\"b\", marker=\"x\", label='valid/loss')\naxes[1].legend(loc='upper right', fontsize=9)\n\nlr = metrics['lr'].dropna().reset_index(drop=True)\n\naxes[2].grid(True)\naxes[2].plot(lr, color=\"g\", marker=\"o\", label='learning rate')\naxes[2].legend(loc='upper right', fontsize=9)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:54:30.106338Z","iopub.execute_input":"2022-04-04T13:54:30.106644Z","iopub.status.idle":"2022-04-04T13:54:30.563181Z","shell.execute_reply.started":"2022-04-04T13:54:30.106610Z","shell.execute_reply":"2022-04-04T13:54:30.562519Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv(PATH + \"sample_submission.csv\")\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:11:24.019088Z","iopub.execute_input":"2022-04-04T13:11:24.019741Z","iopub.status.idle":"2022-04-04T13:11:24.055106Z","shell.execute_reply.started":"2022-04-04T13:11:24.019699Z","shell.execute_reply":"2022-04-04T13:11:24.054248Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv(PATH + \"sample_submission.csv\")\nsub[\"file_path\"] = sub[\"filename\"].apply(lambda image: TEST_DIR + image)\nsub[\"cultivar_index\"] = 0\n\ntest_dataset = SorghumDataset(sub, get_transform('valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T14:43:51.350162Z","iopub.execute_input":"2022-04-04T14:43:51.350512Z","iopub.status.idle":"2022-04-04T14:43:51.370125Z","shell.execute_reply.started":"2022-04-04T14:43:51.350428Z","shell.execute_reply":"2022-04-04T14:43:51.369487Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nmodel.cuda()\nmodel.eval()\n\npredictions = []\nfor batch in tqdm(test_loader):\n    image = batch['image'].cuda()\n    with torch.no_grad():\n        outputs = model(image)\n        preds = outputs.detach().cpu()\n        predictions.append(preds.argmax(1))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:12:03.320056Z","iopub.execute_input":"2022-04-04T13:12:03.320372Z","iopub.status.idle":"2022-04-04T13:29:21.109026Z","shell.execute_reply.started":"2022-04-04T13:12:03.320324Z","shell.execute_reply":"2022-04-04T13:29:21.106873Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"tmp = predictions[0]\nfor i in range(len(predictions) - 1):\n    tmp = torch.cat((tmp, predictions[i+1]))\n    \npredictions = [unique_cultivars[pred] for pred in tmp]\n\nsub = pd.read_csv(PATH + \"sample_submission.csv\")\nsub[\"cultivar\"] = predictions\nsub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:29:24.024942Z","iopub.execute_input":"2022-04-04T13:29:24.025226Z","iopub.status.idle":"2022-04-04T13:29:24.187966Z","shell.execute_reply.started":"2022-04-04T13:29:24.025193Z","shell.execute_reply":"2022-04-04T13:29:24.187278Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}